### Ïù∏Ï≤¥ÏûêÏÑ∏Í∞êÏßÄ

OpenposeÎäî Ïù∏Ï≤¥ ÏûêÏÑ∏ Í∞êÏßÄ(Human pose)Î•º Ìï† Ïàò ÏûàÎäî Ï†ÑÏ≤òÎ¶¨Í∏∞ÏûÖÎãàÎã§. ÏûêÏÑ∏Î•º Í∞êÏßÄÌïòÏó¨ ÏÉàÎ°úÏö¥ Ïù¥ÎØ∏ÏßÄÎ•º ÏÉùÏÑ±Ìï¥ Ï§çÎãàÎã§.

Î®ºÏ†Ä ÏÇ¨ÎûåÏùò Ï†ÑÏã†Ïù¥ Îã¥Í∏¥ Ïù¥ÎØ∏ÏßÄÎ•º Î∂àÎü¨Ïò§Í≤†ÏäµÎãàÎã§.


```python
!pip install controlnet-aux==0.0.1
```

    Requirement already satisfied: controlnet-aux==0.0.1 in /opt/conda/lib/python3.9/site-packages (0.0.1)
    Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.9/site-packages (from controlnet-aux==0.0.1) (4.8.2)
    Requirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from controlnet-aux==0.0.1) (3.12.2)
    Requirement already satisfied: torch in /opt/conda/lib/python3.9/site-packages (from controlnet-aux==0.0.1) (1.12.1)
    Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.9/site-packages (from controlnet-aux==0.0.1) (0.29.3)
    Requirement already satisfied: Pillow in /opt/conda/lib/python3.9/site-packages (from controlnet-aux==0.0.1) (11.1.0)
    Requirement already satisfied: scipy in /opt/conda/lib/python3.9/site-packages (from controlnet-aux==0.0.1) (1.7.1)
    Requirement already satisfied: opencv-python in /opt/conda/lib/python3.9/site-packages (from controlnet-aux==0.0.1) (4.5.3.56)
    Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from controlnet-aux==0.0.1) (1.21.4)
    Requirement already satisfied: einops in /opt/conda/lib/python3.9/site-packages (from controlnet-aux==0.0.1) (0.8.1)
    Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.9/site-packages (from huggingface-hub->controlnet-aux==0.0.1) (6.0)
    Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.9/site-packages (from huggingface-hub->controlnet-aux==0.0.1) (4.62.3)
    Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from huggingface-hub->controlnet-aux==0.0.1) (2.32.3)
    Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.9/site-packages (from huggingface-hub->controlnet-aux==0.0.1) (21.3)
    Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.9/site-packages (from huggingface-hub->controlnet-aux==0.0.1) (2025.3.0)
    Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.9/site-packages (from huggingface-hub->controlnet-aux==0.0.1) (4.12.2)
    Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.9/site-packages (from importlib-metadata->controlnet-aux==0.0.1) (3.6.0)
    Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging>=20.9->huggingface-hub->controlnet-aux==0.0.1) (3.0.6)
    Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.9/site-packages (from requests->huggingface-hub->controlnet-aux==0.0.1) (2.0.8)
    Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->huggingface-hub->controlnet-aux==0.0.1) (2023.5.7)
    Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->huggingface-hub->controlnet-aux==0.0.1) (1.26.7)
    Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->huggingface-hub->controlnet-aux==0.0.1) (2.10)
    [33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv[0m



```python
from diffusers.utils import load_image

openpose_image = load_image(
    "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/person.png"
)
openpose_image
```




    
![png](output_2_0.png)
    




```python
# OpenposeDetectorÎ•º ÏÇ¨Ïö©ÌïòÏó¨ ÏûêÏÑ∏Îßå Ï∂îÏ∂ú
from controlnet_aux import OpenposeDetector

# Ïù∏Ï≤¥Ïùò ÏûêÏÑ∏Î•º Í≤ÄÏ∂úÌïòÎäî ÏÇ¨Ï†Ñ ÌïôÏäµÎêú ControlNet Î∂àÎü¨Ïò§Í∏∞
openpose = OpenposeDetector.from_pretrained("lllyasviel/ControlNet")

# Ïù¥ÎØ∏ÏßÄÏóêÏÑú ÏûêÏÑ∏ Í≤ÄÏ∂ú
openpose_image = openpose(openpose_image)
openpose_image
```

    cuda





    
![png](output_3_1.png)
    




```python
!pip install torch torchvision torchaudio
```

    Requirement already satisfied: torch in /opt/conda/lib/python3.9/site-packages (1.12.1)
    Requirement already satisfied: torchvision in /opt/conda/lib/python3.9/site-packages (0.13.1)
    Requirement already satisfied: torchaudio in /opt/conda/lib/python3.9/site-packages (0.12.1)
    Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.9/site-packages (from torch) (4.12.2)
    Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from torchvision) (1.21.4)
    Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from torchvision) (2.32.3)
    Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.9/site-packages (from torchvision) (11.1.0)
    Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->torchvision) (1.26.7)
    Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.9/site-packages (from requests->torchvision) (2.0.8)
    Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->torchvision) (2023.5.7)
    Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->torchvision) (2.10)
    [33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv[0m



```python
# Openpose Ï†ÑÏ≤òÎ¶¨Í∏∞Î•º ÏÇ¨Ïö©Ìïú Î™®Îç∏ ÌååÏù¥ÌîÑÎùºÏù∏ÏùÑ Î∂àÎü¨ÏòµÎãàÎã§.
import torch
from diffusers import StableDiffusionControlNetPipeline, ControlNetModel 

openpose_controlnet = ControlNetModel.from_pretrained("lllyasviel/sd-controlnet-openpose", torch_dtype=torch.float16)
openpose_pipe = StableDiffusionControlNetPipeline.from_pretrained(
    "runwayml/stable-diffusion-v1-5", controlnet=openpose_controlnet, torch_dtype=torch.float16
)
```

    
    ===================================BUG REPORT===================================
    Welcome to bitsandbytes. For bug reports, please run
    
    python -m bitsandbytes
    
     and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues
    ================================================================================
    bin /opt/conda/lib/python3.9/site-packages/bitsandbytes/libbitsandbytes_cpu.so
    /opt/conda/lib/python3.9/site-packages/bitsandbytes/libbitsandbytes_cpu.so: undefined symbol: cadam32bit_grad_fp32
    CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...
    CUDA SETUP: Highest compute capability among GPUs detected: 7.5
    CUDA SETUP: Detected CUDA version 113
    CUDA SETUP: Loading binary /opt/conda/lib/python3.9/site-packages/bitsandbytes/libbitsandbytes_cpu.so...


    /opt/conda/lib/python3.9/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.
      warn("The installed version of bitsandbytes was compiled without GPU support. "
    /opt/conda/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/usr/local/nvidia/lib')}
      warn(msg)
    /opt/conda/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: /usr/local/nvidia/lib:/usr/local/nvidia/lib64 did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...
      warn(msg)
    /opt/conda/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//10.88.15.153'), PosixPath('tcp'), PosixPath('8888')}
      warn(msg)
    /opt/conda/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('tcp'), PosixPath('//10.88.0.1'), PosixPath('443')}
      warn(msg)
    /opt/conda/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//10.88.15.153'), PosixPath('8887'), PosixPath('tcp')}
      warn(msg)
    /opt/conda/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/aiffel/storage/package')}
      warn(msg)
    /opt/conda/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//matplotlib_inline.backend_inline'), PosixPath('module')}
      warn(msg)
    /opt/conda/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/usr/local/cuda/lib64')}
      warn(msg)
    /opt/conda/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: No libcudart.so found! Install CUDA or the cudatoolkit package (anaconda)!
      warn(msg)



    Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]


    `text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config["id2label"]` will be overriden.



```python
from diffusers import UniPCMultistepScheduler

# OpenPose ÌååÏù¥ÌîÑÎùºÏù∏ Ïä§ÏºÄÏ§ÑÎü¨ ÏÑ§Ï†ï
openpose_pipe.scheduler = UniPCMultistepScheduler.from_config(openpose_pipe.scheduler.config)
openpose_pipe = openpose_pipe.to("cuda")

# ÎèôÏùºÌïú Ïù¥ÎØ∏ÏßÄÎ•º ÏÉùÏÑ±ÌïòÍ∏∞ ÏúÑÌï¥ seed ÏÑ§Ï†ï
generator = torch.manual_seed(1)

# ÌîÑÎ°¨ÌîÑÌä∏ ÏÑ§Ï†ï
prompt = "Superman pose in the sky"
negative_prompt = "Batman pose"

# Ïù¥ÎØ∏ÏßÄÎ•º ÏÉùÏÑ±Ìï©ÎãàÎã§.
openpose_image1 = openpose_pipe(  
    prompt=prompt,
    negative_prompt=negative_prompt,
    num_inference_steps=20,
    generator=generator,
    image=openpose_image  
).images[0]

# ÏÉùÏÑ±Îêú Ïù¥ÎØ∏ÏßÄÎ•º Ï∂úÎ†•Ìï©ÎãàÎã§.
openpose_image1

```


      0%|          | 0/20 [00:00<?, ?it/s]





    
![png](output_6_1.png)
    




```python
# Q. ÌîÑÎ°¨ÌîÑÌä∏Î•º ÏûëÏÑ±ÌïòÍ≥† ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞Î•º Ï°∞Ï†àÌïòÏó¨ Ïù¥ÎØ∏ÏßÄÎ•º ÏÉùÏÑ±Ìï¥ Î≥¥ÏÑ∏Ïöî. 
# ÎèôÏùºÌïú Ïù¥ÎØ∏ÏßÄÎ•º ÏÉùÏÑ±ÌïòÍ∏∞ ÏúÑÌï¥ seed ÏÑ§Ï†ï
generator = torch.manual_seed(1)

# ÌîÑÎ°¨ÌîÑÌä∏ ÏÑ§Ï†ï
prompt = "Batman pose in the Gotham city"
negative_prompt = "Superman pose"

# Ïù¥ÎØ∏ÏßÄÎ•º ÏÉùÏÑ±Ìï©ÎãàÎã§.
openpose_image2 = openpose_pipe(  
    prompt=prompt,
    negative_prompt=negative_prompt,
    num_inference_steps=20,
    generator=generator,
    image=openpose_image  
).images[0]

# ÏÉùÏÑ±Îêú Ïù¥ÎØ∏ÏßÄÎ•º Ï∂úÎ†•Ìï©ÎãàÎã§.
openpose_image2
```


      0%|          | 0/20 [00:00<?, ?it/s]





    
![png](output_7_1.png)
    



### Ïú§Í≥ΩÏÑ† Í≤ÄÏ∂ú + Ïù∏Ï≤¥ ÏûêÏÑ∏ Í∞êÏßÄ
Ïù¥Î≤àÏóêÎäî ÏúÑÏóêÏÑú Ïã§ÏäµÌïú 2Í∞ÄÏßÄÏùò Ï†ÑÏ≤òÎ¶¨Í∏∞Î•º ÎèôÏãúÏóê ÏÇ¨Ïö©Ìï¥ Î≥¥Í≤†ÏäµÎãàÎã§. 2Í∞úÏùò Ï†ÑÏ≤òÎ¶¨Í∏∞Î•º controlnetsÎùºÎäî Î¶¨Ïä§Ìä∏Î°ú ÎßåÎì§Ïñ¥ ÌååÏù¥ÌîÑÎùºÏù∏ÏúºÎ°ú Ï†ÑÎã¨ÌïòÎ©¥ Îê©ÎãàÎã§.

#### Canny ÏïåÍ≥†Î¶¨Ï¶òÏùÑ ÏÇ¨Ïö©Ìïú Ïú§Í≥ΩÏÑ† Í≤ÄÏ∂ú
Î®ºÏ†Ä Canny ÏïåÍ≥†Î¶¨Ï¶òÏúºÎ°ú Ïú§Í≥ΩÏÑ†ÏùÑ Í≤ÄÏ∂úÌï©ÎãàÎã§. Canny ÏïåÍ≥†Î¶¨Ï¶òÏúºÎ°ú Ïú§Í≥ΩÏÑ†ÏùÑ Í≤ÄÏ∂úÌïú Ïù¥ÎØ∏ÏßÄ ÏúÑÏóê Ïù∏Ï≤¥ ÏûêÏÑ∏ Í≤ÄÏ∂ú Ï†ÑÏ≤òÎ¶¨Í∏∞Î•º Ïò¨Î†§Ï§Ñ Í≤ÉÏù¥Í∏∞ ÎïåÎ¨∏Ïóê Ïù∏Ï≤¥ ÏûêÏÑ∏Î•º ÎÑ£Ïñ¥Ï§Ñ Î∂ÄÎ∂ÑÏùÑ Ïù¥ÎØ∏ÏßÄ ÎÇ¥ÏóêÏÑú ÏßÄÏõåÏ£ºÏñ¥Ïïº ÌïúÎã§Îäî Ï†êÏùÑ Ï£ºÏùòÌïòÏÑ∏Ïöî.

ÏßÅÏ†ë ÏïÑÎûòÏùò ÏΩîÎìúÎ•º ÏûëÏÑ±Ìï¥ Î≥¥ÏÑ∏Ïöî.



```python
from diffusers.utils import load_image 
from PIL import Image
import cv2
import numpy as np
from diffusers.utils import load_image

# Q. ÏΩîÎìúÎ•º ÏûëÏÑ±Ìï¥ Î≥¥ÏÑ∏Ïöî.
# Ïù¥ÎØ∏ÏßÄÎ•º Î∂àÎü¨Ïò§ÏÑ∏Ïöî. 
canny_image = load_image(
    "https://image.news1.kr/system/photos/2024/8/9/6816731/high.jpg"
)
canny_image.show()

#threshholdÎ•º ÏßÄÏ†ïÌï©ÎãàÎã§. 
low_threshold = 100
high_threshold = 200

# Ïù¥ÎØ∏ÏßÄÎ•º NumPy Î∞∞Ïó¥Î°ú Î≥ÄÌôòÌï©ÎãàÎã§. 
canny_image = np.array(canny_image)

# Ïù∏Ï≤¥ Í∞êÏßÄ Ìè¨Ï¶àÎ•º ÎÑ£Ïñ¥Ï§Ñ Í∞ÄÏö¥Îç∞ Î∂ÄÎ∂ÑÏùÑ ÏßÄÏõåÏ§çÎãàÎã§. 
zero_start = canny_image.shape[1] // 4
zero_end = zero_start + canny_image.shape[1] // 2
canny_image[:, zero_start:zero_end] = 0

# Ïú§Í≥ΩÏÑ†ÏùÑ Í≤ÄÏ∂úÌïòÍ≥† NumPy Î∞∞Ïó¥ÏùÑ PIL Ïù¥ÎØ∏ÏßÄÎ°ú Î≥ÄÌôòÌï©ÎãàÎã§. 
canny_image = cv2.Canny(canny_image, low_threshold, high_threshold)
canny_image = canny_image[:, :, None]
canny_image = np.concatenate([canny_image, canny_image, canny_image], axis=2)

canny_image = Image.fromarray(canny_image)  # NumPy Î∞∞Ïó¥ÏùÑ PIL Ïù¥ÎØ∏ÏßÄÎ°ú Î≥ÄÌôòÌï©ÎãàÎã§. 

canny_image
```


    
![png](output_9_0.png)
    





    
![png](output_9_1.png)
    




```python
from controlnet_aux import OpenposeDetector
from diffusers.utils import load_image 

# Q. ÏïÑÎûòÏùò ÏΩîÎìúÎ•º ÏûëÏÑ±Ìï¥ Ï£ºÏÑ∏Ïöî.
# Ïù¥ÎØ∏ÏßÄÎ•º Î∂àÎü¨ÏòµÎãàÎã§. 
openpose_image = load_image(
    "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQmMwUMn86eDgMAI9Y7rS0iflF-mAwaU_-u50QLE3IN9TyOrLZbMG0aQvVJyaK0wdVet5k&usqp=CAU"
)
openpose_image.show()
# OpenposeDetectorÎ•º ÏÇ¨Ïö©ÌïòÏó¨ Ïù∏Ï≤¥ ÏûêÏÑ∏Î•º Í≤ÄÏ∂úÌï©ÎãàÎã§. 
openpose = OpenposeDetector.from_pretrained("lllyasviel/ControlNet")
openpose_image = openpose(openpose_image)

openpose_image
```


    
![png](output_10_0.png)
    


    cuda





    
![png](output_10_2.png)
    




```python
from diffusers import StableDiffusionControlNetPipeline, ControlNetModel, UniPCMultistepScheduler  

# Q. ÏΩîÎìúÎ•º ÏûëÏÑ±Ìï¥ Î≥¥ÏÑ∏Ïöî.
# Edge DetectionÍ≥º Openpose, 2Í∞úÏùò Ï†ÑÏ≤òÎ¶¨Í∏∞Î•º controlnetsÎùºÎäî Î¶¨Ïä§Ìä∏Î°ú ÎßåÎì≠ÎãàÎã§. 
# OpenPose & Canny ControlNet Î™®Îç∏ Î∂àÎü¨Ïò§Í∏∞
openpose_controlnet = ControlNetModel.from_pretrained(
    "lllyasviel/sd-controlnet-openpose", torch_dtype=torch.float16)
canny_controlnet = ControlNetModel.from_pretrained(
    "lllyasviel/sd-controlnet-canny", torch_dtype=torch.float16)

# Ïó¨Îü¨ Í∞úÏùò ControlNetÏùÑ Î¶¨Ïä§Ìä∏Î°ú Ï†ÄÏû•
controlnets = [openpose_controlnet, canny_controlnet]

# Î¶¨Ïä§Ìä∏ controlnetsÎ•º ÌååÏù¥ÌîÑÎùºÏù∏ÏúºÎ°ú Ï†ÑÎã¨Ìï©ÎãàÎã§. 
pipe = StableDiffusionControlNetPipeline.from_pretrained(
    "runwayml/stable-diffusion-v1-5", controlnet=controlnets, torch_dtype=torch.float16
)

pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)
pipe = pipe.to("cuda")
```


    Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]


    `text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config["id2label"]` will be overriden.



```python
from PIL import Image

# Ïù¥ÎØ∏ÏßÄ ÌÅ¨Í∏∞Î•º 512x512Î°ú ÎßûÏ∂îÍ∏∞
target_size = (512, 512)

openpose_image = openpose_image.resize(target_size, Image.BILINEAR)
canny_image = canny_image.resize(target_size, Image.BILINEAR)

images = [openpose_image, canny_image]

# ÌîÑÎ°¨ÌîÑÌä∏Î•º ÏûëÏÑ±Ìï©ÎãàÎã§. 
prompt = "a man"
negative_prompt = "without pants"

# seedÎ•º ÏßÄÏ†ïÌï©ÎãàÎã§. 
generator = torch.manual_seed(1)

images = [openpose_image, canny_image]

# Ïù¥ÎØ∏ÏßÄÎ•º ÏÉùÏÑ±Ìï©ÎãàÎã§. 
image = pipe(
    prompt=prompt,
    negative_prompt=negative_prompt,
    num_inference_steps=20,  # ÏÉòÌîåÎßÅ Ïä§ÌÖù ÏÑ§Ï†ï
    generator=generator,
    image=images  # OpenPose & Canny Ïù¥ÎØ∏ÏßÄ Î¶¨Ïä§Ìä∏ ÏûÖÎ†•
).images[0]


# ÏÉùÏÑ±Îêú Ïù¥ÎØ∏ÏßÄÎ•º Ï†ÄÏû•Ìï©ÎãàÎã§.
image.save("/aiffel/aiffel/diffusers/multi_controlnet_output.png")

# ÏÉùÏÑ±Îêú Ïù¥ÎØ∏ÏßÄÎ•º Ï∂úÎ†•Ìï©ÎãàÎã§.  
image
```


      0%|          | 0/20 [00:00<?, ?it/s]





    
![png](output_12_1.png)
    




```python
from PIL import Image

# Ïù¥ÎØ∏ÏßÄ ÌÅ¨Í∏∞Î•º 512x512Î°ú ÎßûÏ∂îÍ∏∞
target_size = (512, 512)

openpose_image = openpose_image.resize(target_size, Image.BILINEAR)
canny_image = canny_image.resize(target_size, Image.BILINEAR)

images = [openpose_image, canny_image]

# ÌîÑÎ°¨ÌîÑÌä∏Î•º ÏûëÏÑ±Ìï©ÎãàÎã§. 
prompt = "a man"
negative_prompt = "with suits"

# seedÎ•º ÏßÄÏ†ïÌï©ÎãàÎã§. 
generator = torch.manual_seed(1)

images = [openpose_image, canny_image]

# Ïù¥ÎØ∏ÏßÄÎ•º ÏÉùÏÑ±Ìï©ÎãàÎã§. 
image = pipe(
    prompt=prompt,
    negative_prompt=negative_prompt,
    num_inference_steps=20,  # ÏÉòÌîåÎßÅ Ïä§ÌÖù ÏÑ§Ï†ï
    generator=generator,
    image=images  # OpenPose & Canny Ïù¥ÎØ∏ÏßÄ Î¶¨Ïä§Ìä∏ ÏûÖÎ†•
).images[0]


# ÏÉùÏÑ±Îêú Ïù¥ÎØ∏ÏßÄÎ•º Ï†ÄÏû•Ìï©ÎãàÎã§.
image.save("/aiffel/aiffel/diffusers/multi_controlnet_output.png")

# ÏÉùÏÑ±Îêú Ïù¥ÎØ∏ÏßÄÎ•º Ï∂úÎ†•Ìï©ÎãàÎã§.  
image
```


      0%|          | 0/20 [00:00<?, ?it/s]





    
![png](output_13_1.png)
    



## Îã§Î•∏Í≤É ÏãúÎèÑ


```python
from diffusers.utils import load_image 
from PIL import Image
import cv2
import numpy as np
from diffusers.utils import load_image

# Q. ÏΩîÎìúÎ•º ÏûëÏÑ±Ìï¥ Î≥¥ÏÑ∏Ïöî.
# Ïù¥ÎØ∏ÏßÄÎ•º Î∂àÎü¨Ïò§ÏÑ∏Ïöî. 
canny_image = load_image(
    "https://seoartgallery.com/wp-content/uploads/2016/07/%EB%B0%98%EA%B3%A0%ED%9D%90-%EC%B4%88%EC%83%81%ED%99%94.jpg"
)
canny_image.show()
#threshholdÎ•º ÏßÄÏ†ïÌï©ÎãàÎã§. 
low_threshold = 100
high_threshold = 200

# Ïù¥ÎØ∏ÏßÄÎ•º NumPy Î∞∞Ïó¥Î°ú Î≥ÄÌôòÌï©ÎãàÎã§. 
canny_image = np.array(canny_image)

# Ïù∏Ï≤¥ Í∞êÏßÄ Ìè¨Ï¶àÎ•º ÎÑ£Ïñ¥Ï§Ñ Í∞ÄÏö¥Îç∞ Î∂ÄÎ∂ÑÏùÑ ÏßÄÏõåÏ§çÎãàÎã§. 
zero_start = canny_image.shape[1] // 4
zero_end = zero_start + canny_image.shape[1] // 2
canny_image[:, zero_start:zero_end] = 0

# Ïú§Í≥ΩÏÑ†ÏùÑ Í≤ÄÏ∂úÌïòÍ≥† NumPy Î∞∞Ïó¥ÏùÑ PIL Ïù¥ÎØ∏ÏßÄÎ°ú Î≥ÄÌôòÌï©ÎãàÎã§. 
canny_image = cv2.Canny(canny_image, low_threshold, high_threshold)
canny_image = canny_image[:, :, None]
canny_image = np.concatenate([canny_image, canny_image, canny_image], axis=2)

canny_image = Image.fromarray(canny_image)  # NumPy Î∞∞Ïó¥ÏùÑ PIL Ïù¥ÎØ∏ÏßÄÎ°ú Î≥ÄÌôòÌï©ÎãàÎã§. 

canny_image
```


    
![png](output_15_0.png)
    





    
![png](output_15_1.png)
    




```python
from PIL import Image

# Ïù¥ÎØ∏ÏßÄ ÌÅ¨Í∏∞Î•º 512x512Î°ú ÎßûÏ∂îÍ∏∞
target_size = (512, 512)

openpose_image = openpose_image.resize(target_size, Image.BILINEAR)
canny_image = canny_image.resize(target_size, Image.BILINEAR)

images = [openpose_image, canny_image]

# ÌîÑÎ°¨ÌîÑÌä∏Î•º ÏûëÏÑ±Ìï©ÎãàÎã§. 
prompt = "a man"
negative_prompt = "without pants"

# seedÎ•º ÏßÄÏ†ïÌï©ÎãàÎã§. 
generator = torch.manual_seed(1)

images = [openpose_image, canny_image]

# Ïù¥ÎØ∏ÏßÄÎ•º ÏÉùÏÑ±Ìï©ÎãàÎã§. 
image = pipe(
    prompt=prompt,
    negative_prompt=negative_prompt,
    num_inference_steps=20,  # ÏÉòÌîåÎßÅ Ïä§ÌÖù ÏÑ§Ï†ï
    generator=generator,
    image=images  # OpenPose & Canny Ïù¥ÎØ∏ÏßÄ Î¶¨Ïä§Ìä∏ ÏûÖÎ†•
).images[0]


# ÏÉùÏÑ±Îêú Ïù¥ÎØ∏ÏßÄÎ•º Ï†ÄÏû•Ìï©ÎãàÎã§.
image.save("/aiffel/aiffel/diffusers/multi_controlnet_output.png")

# ÏÉùÏÑ±Îêú Ïù¥ÎØ∏ÏßÄÎ•º Ï∂úÎ†•Ìï©ÎãàÎã§.  
image
```


      0%|          | 0/20 [00:00<?, ?it/s]





    
![png](output_16_1.png)
    




```python
from PIL import Image

# Ïù¥ÎØ∏ÏßÄ ÌÅ¨Í∏∞Î•º 512x512Î°ú ÎßûÏ∂îÍ∏∞
target_size = (512, 512)

openpose_image = openpose_image.resize(target_size, Image.BILINEAR)
canny_image = canny_image.resize(target_size, Image.BILINEAR)

images = [openpose_image, canny_image]

# ÌîÑÎ°¨ÌîÑÌä∏Î•º ÏûëÏÑ±Ìï©ÎãàÎã§. 
prompt = "a man"
negative_prompt = "with suits"

# seedÎ•º ÏßÄÏ†ïÌï©ÎãàÎã§. 
generator = torch.manual_seed(1)

images = [openpose_image, canny_image]

# Ïù¥ÎØ∏ÏßÄÎ•º ÏÉùÏÑ±Ìï©ÎãàÎã§. 
image = pipe(
    prompt=prompt,
    negative_prompt=negative_prompt,
    num_inference_steps=20,  # ÏÉòÌîåÎßÅ Ïä§ÌÖù ÏÑ§Ï†ï
    generator=generator,
    image=images  # OpenPose & Canny Ïù¥ÎØ∏ÏßÄ Î¶¨Ïä§Ìä∏ ÏûÖÎ†•
).images[0]


# ÏÉùÏÑ±Îêú Ïù¥ÎØ∏ÏßÄÎ•º Ï†ÄÏû•Ìï©ÎãàÎã§.
image.save("/aiffel/aiffel/diffusers/multi_controlnet_output.png")

# ÏÉùÏÑ±Îêú Ïù¥ÎØ∏ÏßÄÎ•º Ï∂úÎ†•Ìï©ÎãàÎã§.  
image
```


      0%|          | 0/20 [00:00<?, ?it/s]





    
![png](output_17_1.png)
    



### Ï†úÎåÄÎ°ú Îêú Î∞∞Í≤ΩÏùÑ ÎÑ£Í∏∞


```python
from diffusers.utils import load_image 
from PIL import Image
import cv2
import numpy as np
from diffusers.utils import load_image

# Q. ÏΩîÎìúÎ•º ÏûëÏÑ±Ìï¥ Î≥¥ÏÑ∏Ïöî.
# Ïù¥ÎØ∏ÏßÄÎ•º Î∂àÎü¨Ïò§ÏÑ∏Ïöî. 
canny_image = load_image(
    "https://i.pinimg.com/236x/4b/48/f7/4b48f7784c5b7d84c7190e5d1d977e46.jpg"
)
canny_image.show()

#threshholdÎ•º ÏßÄÏ†ïÌï©ÎãàÎã§. 
low_threshold = 50
high_threshold = 100

# Ïù¥ÎØ∏ÏßÄÎ•º NumPy Î∞∞Ïó¥Î°ú Î≥ÄÌôòÌï©ÎãàÎã§. 
canny_image = np.array(canny_image)

# Ïù∏Ï≤¥ Í∞êÏßÄ Ìè¨Ï¶àÎ•º ÎÑ£Ïñ¥Ï§Ñ Í∞ÄÏö¥Îç∞ Î∂ÄÎ∂ÑÏùÑ ÏßÄÏõåÏ§çÎãàÎã§. 
zero_start = canny_image.shape[1] 
zero_end = zero_start + canny_image.shape[1] 
canny_image[:, zero_start:zero_end] = 0

# Ïú§Í≥ΩÏÑ†ÏùÑ Í≤ÄÏ∂úÌïòÍ≥† NumPy Î∞∞Ïó¥ÏùÑ PIL Ïù¥ÎØ∏ÏßÄÎ°ú Î≥ÄÌôòÌï©ÎãàÎã§. 
canny_image = cv2.Canny(canny_image, low_threshold, high_threshold)
canny_image = canny_image[:, :, None]
canny_image = np.concatenate([canny_image, canny_image, canny_image], axis=2)

canny_image = Image.fromarray(canny_image)  # NumPy Î∞∞Ïó¥ÏùÑ PIL Ïù¥ÎØ∏ÏßÄÎ°ú Î≥ÄÌôòÌï©ÎãàÎã§. 

canny_image
```


    
![png](output_19_0.png)
    





    
![png](output_19_1.png)
    




```python
from PIL import Image

# Ïù¥ÎØ∏ÏßÄ ÌÅ¨Í∏∞Î•º 512x512Î°ú ÎßûÏ∂îÍ∏∞
target_size = (512, 512)

openpose_image = openpose_image.resize(target_size, Image.BILINEAR)
canny_image = canny_image.resize(target_size, Image.BILINEAR)

images = [openpose_image, canny_image]

# ÌîÑÎ°¨ÌîÑÌä∏Î•º ÏûëÏÑ±Ìï©ÎãàÎã§. 
prompt = "a man"
negative_prompt = "with suits"

# seedÎ•º ÏßÄÏ†ïÌï©ÎãàÎã§. 
generator = torch.manual_seed(1)

images = [openpose_image, canny_image]

# Ïù¥ÎØ∏ÏßÄÎ•º ÏÉùÏÑ±Ìï©ÎãàÎã§. 
image = pipe(
    prompt=prompt,
    negative_prompt=negative_prompt,
    num_inference_steps=20,  # ÏÉòÌîåÎßÅ Ïä§ÌÖù ÏÑ§Ï†ï
    generator=generator,
    image=images  # OpenPose & Canny Ïù¥ÎØ∏ÏßÄ Î¶¨Ïä§Ìä∏ ÏûÖÎ†•
).images[0]


# ÏÉùÏÑ±Îêú Ïù¥ÎØ∏ÏßÄÎ•º Ï†ÄÏû•Ìï©ÎãàÎã§.
image.save("/aiffel/aiffel/diffusers/multi_controlnet_output.png")

# ÏÉùÏÑ±Îêú Ïù¥ÎØ∏ÏßÄÎ•º Ï∂úÎ†•Ìï©ÎãàÎã§.  
image
```


      0%|          | 0/20 [00:00<?, ?it/s]





    
![png](output_20_1.png)
    




```python

```
